import os
import re
import google.generativeai as genai  # Google ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import List, Optional
from dotenv import load_dotenv

# .env íŒŒì¼ì„ ì½ì–´ì™€ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡
load_dotenv()

from backend.core.config import settings
from backend.db.session import get_db
from backend.db.models import Analysis, AnalysisType, VectorDocument
from backend.services.analysis.embedding_engine import EmbeddingSearchEngine

router = APIRouter()

class ConsistencyRequest(BaseModel):
    current_text: str
    novel_id: int
    current_scene_index: Optional[int] = None

class StoryValidator:
    def __init__(self, db, engine):
        self.db = db
        self.engine = engine  # EmbeddingSearchEngine ì¸ìŠ¤í„´ìŠ¤
        
        # .envì˜ GOOGLE_API_KEY ì‚¬ìš©
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        
        if not api_key:
            raise ValueError("API í‚¤(GOOGLE_API_KEY)ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # Google Gemini ì„¤ì •
        genai.configure(api_key=api_key)
        
        # ëª¨ë¸ëª… ì„¤ì • (ì˜¤íƒ€ ë°©ì§€ ë¡œì§ í¬í•¨)
        model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
        if "2.5" in model_name: 
            model_name = "gemini-2.5-flash"
            
        self.model = genai.GenerativeModel(model_name)

    def run_analysis(self, current_text: str, novel_id: int, current_scene_index: Optional[int] = None):
        """
        [ì„¤ì • ì˜¤ë¥˜ ë¶„ì„ ë¡œì§]
        1. Pinecone ê²€ìƒ‰ì„ í†µí•œ ìœ ì‚¬ ë§¥ë½ ì¶”ì¶œ
        2. DBì˜ ëª¨ë“  ì”¬ ìš”ì•½ë³¸ ë¡œë“œ
        3. ë°”ì´ë¸” ì„¤ì • ë¡œë“œ
        4. Gemini í†µí•© ë¶„ì„
        """
        
        # STEP 1: Pinecone ë§¥ë½ ê²€ìƒ‰ (í•¨ìˆ˜ëª…ì„ searchë¡œ ìˆ˜ì •)
        try:
            # embedding_engine.pyì˜ search(query, novel_id, top_k) í˜¸ì¶œ
            search_hits = self.engine.search(query=current_text, novel_id=novel_id, top_k=3)
            
            # ê²€ìƒ‰ëœ ê²°ê³¼ì—ì„œ ìš”ì•½ë¬¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë¬¸ìì—´í™”
            context_str = ""
            for hit in search_hits:
                summary = hit['document'].get('summary', 'ìš”ì•½ ì—†ìŒ')
                context_str += f"- ê´€ë ¨ ë§¥ë½: {summary}\n"
            print(f"âœ… Pinecone ê²€ìƒ‰ ì™„ë£Œ. {len(search_hits)}ê°œì˜ ìœ ì‚¬ ë§¥ë½ ì¶”ì¶œë¨.")
        except Exception as e:
            print(f"âŒ Pinecone ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            context_str = "ì°¸ê³ í•  ê³¼ê±° ë§¥ë½ì´ ì—†ìŠµë‹ˆë‹¤."

        # STEP 2: DBì—ì„œ ì „ì²´ ìŠ¤í† ë¦¬ë³´ë“œ(ì”¬ ìš”ì•½) ê°€ì ¸ì˜¤ê¸°
        all_docs = self.db.query(VectorDocument).filter(
            VectorDocument.novel_id == novel_id
        ).order_by(VectorDocument.chunk_index).all()
        
        storyboard_str = ""
        if not all_docs:
            storyboard_str = "ê¸°ë¡ëœ ìŠ¤í† ë¦¬ë³´ë“œê°€ ì—†ìŠµë‹ˆë‹¤."
        else:
            for doc in all_docs:
                scene_data = doc.metadata_json
                idx = doc.chunk_index
                summary = scene_data.get('summary', 'ìš”ì•½ ì—†ìŒ')
                prefix = "[í˜„ì¬ ìˆ˜ì • ì¤‘ì¸ ìœ„ì¹˜] " if idx == current_scene_index else ""
                storyboard_str += f"ì”¬ {idx}: {prefix}{summary}\n"

        # STEP 3: PostgreSQL ë°”ì´ë¸” ì¡°íšŒ
        bible_record = self.db.query(Analysis).filter(
            Analysis.novel_id == novel_id,
            Analysis.analysis_type == AnalysisType.CHARACTER
        ).first()
        
        bible_settings = bible_record.result if bible_record else "ë“±ë¡ëœ ìºë¦­í„° ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤."

        # STEP 4: Gemini í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        print(f"ğŸš€ Gemini ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘... (novel_id: {novel_id})")
        return self.generate_llm_report(current_text, storyboard_str, context_str, bible_settings)

    def generate_llm_report(self, text, storyboard, context, bible):
        prompt = f"""ë„ˆëŠ” ì†Œì„¤ ì „ë¬¸ í¸ì§‘ìì´ì ì„¤ì • ê²€ìˆ˜ ì „ë¬¸ê°€ì•¼.
ì‘ê°€ê°€ ì‘ì„±í•œ [ì „ì²´ í…ìŠ¤íŠ¸]ë¥¼ ë¶„ì„í•˜ì—¬ [ì„¤ì • ë°”ì´ë¸”] ë° [ì „ì²´ íë¦„]ê³¼ ì¶©ëŒí•˜ê±°ë‚˜ ì–´ìƒ‰í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì§€ì í•´ì¤˜.

[ì„¤ì • ë°”ì´ë¸”]:
{bible}

[ì „ì²´ ìŠ¤í† ë¦¬ë³´ë“œ]:
{storyboard}

[ê²€ìƒ‰ëœ ìœ ì‚¬ ë§¥ë½]:
{context}

[ì „ì²´ í…ìŠ¤íŠ¸]:
{text}

### ë¶„ì„ ë¯¸ì…˜:
1. [ì „ì²´ í…ìŠ¤íŠ¸] ì¤‘ì—ì„œ **ì˜¤ë¥˜ë‚˜ ëª¨ìˆœì´ ìˆëŠ” êµ¬ì²´ì ì¸ ë¬¸ì¥**ì„ í•˜ë‚˜ ì´ìƒ ì°¾ì•„ë‚´ë¼.
2. ì°¾ì•„ë‚¸ ë¬¸ì¥ì„ **[í˜„ì¬ ë¬¸ì¥]** í•­ëª©ì— ì •í™•íˆ ë³µì‚¬í•´ì„œ ë„£ì–´ë¼. ë§Œì•½ ì—¬ëŸ¬ ë¬¸ì¥ì´ ë¬¸ì œë¼ë©´ ê°€ì¥ í•µì‹¬ì ì¸ ë¬¸ì¥ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜ í•©ì³ì„œ ì ì–´ë¼.
3. í•´ë‹¹ ë¬¸ì¥ì´ ì™œ ë¬¸ì œì¸ì§€ ë¶„ì„ ê¸°ì¤€ì— ë§ì¶° ì„¤ëª…í•´ë¼.
4. ë§Œì•½ íŠ¹ë³„í•œ ë¬¸ì œê°€ ì—†ë‹¤ë©´, [í˜„ì¬ ë¬¸ì¥]ì—ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì²« ë¬¸ì¥ì„ ì ê³  ë¦¬í¬íŠ¸ í•­ëª©ì— "íŠ¹ì´ ì‚¬í•­ ì—†ìŒ"ì´ë¼ê³  ì ì–´ë¼.

### ë¦¬í¬íŠ¸ ì–‘ì‹:
#### ### ì†Œì„¤ í¸ì§‘ ë¦¬í¬íŠ¸
**[í˜„ì¬ ë¬¸ì¥]:** "ë¬¸ì œë˜ëŠ” ë¬¸ì¥ì„ ì—¬ê¸°ì— ë³µì‚¬"

1. âš ï¸ ì„¤ì • ì¶©ëŒ: (ë‚´ìš©)

2. âš™ï¸ ê°œì—°ì„± ê²½ê³ : (ë‚´ìš©)

3. ğŸ—£ï¸ ë³´ì´ìŠ¤ ë¶ˆì¼ì¹˜: (ë‚´ìš©)

**[ì¢…í•© ì˜ê²¬]:** í•´ê²°ì±… ì œì‹œ.
"""
        
        try:
            response = self.model.generate_content(prompt)
            report_content = response.text
            
            # [í˜„ì¬ ë¬¸ì¥] ì¶”ì¶œìš© ì •ê·œì‹ (ìœ ì—°í•˜ê²Œ ë§¤ì¹­)
            target_match = re.search(r'\*\*\[í˜„ì¬ ë¬¸ì¥\]:\*\* "(.*?)"', report_content)
            if not target_match:
                target_match = re.search(r'\[í˜„ì¬ ë¬¸ì¥\]: (.*)', report_content)
                
            target_sentence = target_match.group(1).strip() if target_match else ""
            
            # ë”°ì˜´í‘œ ì œê±°
            target_sentence = target_sentence.strip('"').strip("'")

            return {
                "report": report_content,
                "target_sentence": target_sentence,
                "status": "success"
            }
        except Exception as e:
            print(f"âŒ Gemini ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"report": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "status": "error"}

# ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_search_engine = None

def get_search_engine() -> EmbeddingSearchEngine:
    global _search_engine
    if _search_engine is None:
        try:
            _search_engine = EmbeddingSearchEngine()
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=503, detail="ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨")
    else:
        print("âœ… ê²€ìƒ‰ ì—”ì§„ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì—”ì§„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    return _search_engine

@router.post("/check")
async def check_consistency(
    request_data: ConsistencyRequest,
    db: Session = Depends(get_db),
    engine: EmbeddingSearchEngine = Depends(get_search_engine)
):
    try:
        print(f"ğŸ” Consistency check ìš”ì²­ ìˆ˜ì‹ : novel_id={request_data.novel_id}")
        validator = StoryValidator(db, engine)
        result = validator.run_analysis(
            request_data.current_text, 
            request_data.novel_id,
            request_data.current_scene_index
        )
        print("âœ… Consistency check ì™„ë£Œ ë° ì‘ë‹µ ì „ì†¡")
        return result
    except Exception as e:
        print(f"âŒ Consistency check failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))