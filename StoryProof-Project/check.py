from fastapi import APIRouter
from pinecone import Pinecone
from openai import OpenAI
import psycopg2

router = APIRouter()
pc = Pinecone(api_key="pcsk_5fsJcc_LVyYc2y1Y9Ab8bSXQvApZGNBV6PMh7H9iqWJ82WjbJTb9HPW3Pzr85AVCpf9xU2")
index = pc.Index("storyboard-index")
client = OpenAI(api_key="your-openai-api-key")

@router.post("/check-consistency")
async def check_consistency(current_text: str, novel_id: int):
    # 1. Pineconeì—ì„œ ê´€ë ¨ ìŠ¤í† ë¦¬ë³´ë“œ ë§¥ë½ ê²€ìƒ‰ (Vector)
    # ì´ë¯¸ì§€ì—ì„œ ì„ íƒí•œ multilingual-e5-large ëª¨ë¸ ì‚¬ìš© ê°€ì •
    search_res = index.query(
        vector=get_embedding(current_text), # ì„ë² ë”© í•¨ìˆ˜
        top_k=3,
        include_metadata=True
    )
    story_context = [res.metadata['text'] for res in search_res.matches]

    # 2. PostgreSQLì—ì„œ ë°”ì´ë¸” ì„¤ì • ì¡°íšŒ (Structured)
    # ë³¸ë¬¸ì—ì„œ ì´ë¦„ ë“±ì„ ì¶”ì¶œí•˜ì—¬ ê²€ìƒ‰ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    bible_data = get_bible_from_db(novel_id) 

    # 3. LLMì—ê²Œ 3ê°€ì§€ í¬ì¸íŠ¸ ê²€ì‚¬ ìš”ì²­
    report = client.chat.completions.create(
        model="gemini-2.5-flash",
        messages=[
            {"role": "system", "content": f"""ë„ˆëŠ” ì†Œì„¤ êµì • ì „ë¬¸ê°€ì•¼. 
            ì•„ë˜ [ë°”ì´ë¸” ì„¤ì •]ê³¼ [ê³¼ê±° ì¤„ê±°ë¦¬]ë¥¼ ì°¸ê³ í•´ì„œ [í˜„ì¬ ë¬¸ì¥]ì˜ ì˜¤ë¥˜ë¥¼ ì°¾ì•„ì¤˜.
            
            ë¶„ì„ í•­ëª©:
            1. âš ï¸ ì„¤ì • ì¶©ëŒ: ë°”ì´ë¸”ì˜ ì™¸ì–‘/ê³ ìœ ì„¤ì • ìœ„ë°˜
            2. âš™ï¸ ê°œì—°ì„± ê²½ê³ : ê³¼ê±° ì¤„ê±°ë¦¬ì˜ ìƒíƒœ(ë¶€ìƒ, ë§ˆë‚˜ ë“±) ëŒ€ë¹„ ì–´ìƒ‰í•œ í–‰ë™
            3. ğŸ—£ï¸ ë³´ì´ìŠ¤ ë¶ˆì¼ì¹˜: ìºë¦­í„° í˜ë¥´ì†Œë‚˜ì™€ ë§íˆ¬ ê°€ì´ë“œ ìœ„ë°˜
            
            [ë°”ì´ë¸” ì„¤ì •]: {bible_data}
            [ê³¼ê±° ì¤„ê±°ë¦¬]: {story_context}
            """},
            {"role": "user", "content": f"í˜„ì¬ ì‘ì„± ì¤‘ì¸ ë¬¸ì¥: {current_text}"}
        ]
    )

    return {"report": report.choices[0].message.content}