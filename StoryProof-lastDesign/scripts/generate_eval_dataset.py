"""
RAG & Agent í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±ê¸°
================================
Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œì„¤ í…ìŠ¤íŠ¸ë¡œë¶€í„° RAG QA ìŒ + Agent ì¼ê´€ì„± ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/generate_eval_dataset.py                    # ê¸°ë³¸ ì‹¤í–‰
    python scripts/generate_eval_dataset.py --dry-run          # API í˜¸ì¶œ ì—†ì´ êµ¬ì¡° ê²€ì¦
    python scripts/generate_eval_dataset.py --novels 3         # ì†Œì„¤ 3ê°œë§Œ ì‚¬ìš©
    python scripts/generate_eval_dataset.py --qa-per-novel 5   # ì†Œì„¤ë‹¹ QA 5ê°œ
"""

import os
import sys
import json
import random
import argparse
from typing import List, Dict
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from google import genai
from dotenv import load_dotenv

load_dotenv()

# ===== ì„¤ì • =====
NOVEL_DIR = "novel_corpus_kr"
OUTPUT_FILE = "eval_dataset.json"

# í‰ê°€ì— ì‚¬ìš©í•  ì†Œì„¤ ëª©ë¡ (ë‹¤ì–‘í•œ ì¥ë¥´ í¬í•¨)
DEFAULT_NOVELS = [
    "KR_fantasy_alice.txt",
    "KR_romance_jane.txt",
    "KR_mystery_sherlock.txt",
    "KR_sf_frankenstein.txt",
    "KR_horror_jekyll.txt",
]


def get_gemini_client():
    """Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    return genai.Client(api_key=api_key)


def load_novel_text(filepath: str) -> str:
    """ì†Œì„¤ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()


def extract_text_samples(text: str, num_samples: int = 3, sample_size: int = 5000) -> List[str]:
    """
    ì†Œì„¤ í…ìŠ¤íŠ¸ì—ì„œ ê· ë“±í•˜ê²Œ ë¶„ì‚°ëœ ìƒ˜í”Œ ì¶”ì¶œ
    ì•ë¶€ë¶„, ì¤‘ê°„, ë’·ë¶€ë¶„ì—ì„œ ê°ê° ì¶”ì¶œí•˜ì—¬ ë‹¤ì–‘í•œ ë‚´ìš© ì»¤ë²„
    """
    text_len = len(text)
    if text_len < sample_size:
        return [text]
    
    samples = []
    positions = [0, text_len // 3, (text_len * 2) // 3]
    
    for pos in positions[:num_samples]:
        end = min(pos + sample_size, text_len)
        samples.append(text[pos:end])
    
    return samples


def generate_rag_qa_pairs(client, novel_title: str, text_chunk: str, num_pairs: int = 5) -> List[Dict]:
    """
    RAG í‰ê°€ìš© QA ìŒ ìƒì„±
    
    ì¹´í…Œê³ ë¦¬:
    - factual: ì‚¬ì‹¤ ê¸°ë°˜ ì§ˆë¬¸ (ëˆ„ê°€, ì–´ë””ì„œ, ë¬´ì—‡ì„)
    - reasoning: ì¶”ë¡  í•„ìš” ì§ˆë¬¸ (ì™œ, ì–´ë–»ê²Œ)
    - detail: ì„¸ë¶€ ë¬˜ì‚¬/ëŒ€ì‚¬ ê´€ë ¨ ì§ˆë¬¸
    """
    prompt = f"""ë‹¤ìŒ ì†Œì„¤ì˜ ì¼ë¶€ë¥¼ ì½ê³ , ì´ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ ë‹µë³€(QA) ìŒì„ {num_pairs}ê°œ ìƒì„±í•˜ì„¸ìš”.

[ì†Œì„¤ ì œëª©]: {novel_title}

[ë‚´ìš©]:
{text_chunk[:8000]}

[ìš”êµ¬ì‚¬í•­]
1. ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:
   - "factual": ì‚¬ì‹¤ ê¸°ë°˜ (ëˆ„ê°€, ì–´ë””ì„œ, ë¬´ì—‡ì„ í–ˆëŠ”ì§€)
   - "reasoning": ì¶”ë¡ /ë¶„ì„ (ì™œ, ì–´ë–¤ ì˜ë¯¸ì¸ì§€)
   - "detail": ì„¸ë¶€ ë¬˜ì‚¬ (ëŒ€ì‚¬, ì™¸ëª¨, ê°ì • í‘œí˜„ ë“±)
2. ë‹µë³€ì€ ë³¸ë¬¸ì— ê·¼ê±°í•˜ì—¬ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. source_segmentì—ëŠ” ì •ë‹µì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë³¸ë¬¸ ë¬¸ì¥ì„ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”.

[ì¶œë ¥: JSON ë°°ì—´]
[
    {{
        "question": "ì§ˆë¬¸ ë‚´ìš©",
        "answer": "ë‹µë³€ ë‚´ìš©",
        "source_segment": "ë³¸ë¬¸ì—ì„œ ì¸ìš©í•œ ê·¼ê±° ë¬¸ì¥",
        "category": "factual|reasoning|detail"
    }}
]"""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config={'response_mime_type': 'application/json'}
        )
        results = json.loads(response.text)
        # ì¹´í…Œê³ ë¦¬ ìœ íš¨ì„± ê²€ì‚¬
        valid_categories = {"factual", "reasoning", "detail"}
        for r in results:
            if r.get("category") not in valid_categories:
                r["category"] = "factual"
        return results
    except Exception as e:
        print(f"  âš ï¸ RAG QA ìƒì„± ì‹¤íŒ¨ ({novel_title}): {e}")
        return []


def generate_agent_scenarios(client, novel_title: str, text_chunk: str, num_pairs: int = 4) -> List[Dict]:
    """
    Agent í‰ê°€ìš© ì¼ê´€/ë¹„ì¼ê´€ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    
    ì‹œë‚˜ë¦¬ì˜¤ ìœ í˜•:
    - consistent: ì„¤ì •ê³¼ ì¼ì¹˜í•˜ëŠ” ë¬¸ì¥
    - inconsistent: ì„¤ì •ê³¼ ëª¨ìˆœë˜ëŠ” ë¬¸ì¥ (ì„¤ì • íŒŒê´´)
    """
    prompt = f"""ë‹¤ìŒ ì†Œì„¤ì˜ ì¼ë¶€ë¥¼ ì½ê³ , ì„¤ì • ì¼ê´€ì„± ê²€ì‚¬ í…ŒìŠ¤íŠ¸ìš© ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.

[ì†Œì„¤ ì œëª©]: {novel_title}

[ë‚´ìš©]:
{text_chunk[:8000]}

[ìš”êµ¬ì‚¬í•­]
1. "consistent" {num_pairs // 2}ê°œ: ì†Œì„¤ì˜ ì„¤ì •/ì„¸ê³„ê´€ê³¼ ì¼ì¹˜í•˜ëŠ” ë¬¸ì¥
2. "inconsistent" {num_pairs // 2}ê°œ: ì†Œì„¤ì˜ ì„¤ì •/ì„¸ê³„ê´€ê³¼ ëª…ë°±íˆ ëª¨ìˆœë˜ëŠ” ë¬¸ì¥
   - ìºë¦­í„° ì„±ê²© ë³€ê²½, ì¥ì†Œ ì„¤ì • ì˜¤ë¥˜, ì‹œëŒ€ ëª¨ìˆœ ë“±ì„ í¬í•¨
3. inconsistentì—ëŠ” ì–´ë–¤ ì„¤ì •ê³¼ ì¶©ëŒí•˜ëŠ”ì§€ explanationì„ í¬í•¨í•˜ì„¸ìš”.

[ì¶œë ¥: JSON ë°°ì—´]
[
    {{
        "input_text": "í…ŒìŠ¤íŠ¸í•  ë¬¸ì¥ (2-3ë¬¸ì¥)",
        "expected_status": "ì„¤ì • ì¼ì¹˜" ë˜ëŠ” "ì„¤ì • íŒŒê´´ ê°ì§€",
        "scenario_type": "consistent" ë˜ëŠ” "inconsistent",
        "explanation": "ì¼ê´€/ë¹„ì¼ê´€ì˜ ì´ìœ  ì„¤ëª…"
    }}
]"""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config={'response_mime_type': 'application/json'}
        )
        results = json.loads(response.text)
        # ìœ íš¨ì„± ê²€ì‚¬
        for r in results:
            if r.get("scenario_type") not in {"consistent", "inconsistent"}:
                r["scenario_type"] = "consistent"
            if r.get("scenario_type") == "consistent":
                r["expected_status"] = "ì„¤ì • ì¼ì¹˜"
            else:
                r["expected_status"] = "ì„¤ì • íŒŒê´´ ê°ì§€"
        return results
    except Exception as e:
        print(f"  âš ï¸ Agent ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹¤íŒ¨ ({novel_title}): {e}")
        return []


def generate_dry_run_data(novels: List[str]) -> Dict:
    """--dry-run ëª¨ë“œ: API í˜¸ì¶œ ì—†ì´ ë”ë¯¸ ë°ì´í„° ìƒì„±"""
    dataset = {"rag_eval": [], "agent_eval": []}
    
    for novel in novels:
        # RAG ë”ë¯¸ ë°ì´í„°
        dataset["rag_eval"].append({
            "question": f"[DRY-RUN] {novel}ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
            "answer": "[DRY-RUN] í…ŒìŠ¤íŠ¸ ë‹µë³€",
            "source_segment": "[DRY-RUN] í…ŒìŠ¤íŠ¸ ê·¼ê±° ë¬¸ì¥",
            "category": "factual",
            "novel_filename": novel
        })
        # Agent ë”ë¯¸ ë°ì´í„°
        dataset["agent_eval"].extend([
            {
                "input_text": f"[DRY-RUN] {novel} ì¼ê´€ ì‹œë‚˜ë¦¬ì˜¤",
                "expected_status": "ì„¤ì • ì¼ì¹˜",
                "scenario_type": "consistent",
                "explanation": "[DRY-RUN] í…ŒìŠ¤íŠ¸ ì„¤ëª…",
                "novel_filename": novel
            },
            {
                "input_text": f"[DRY-RUN] {novel} ë¹„ì¼ê´€ ì‹œë‚˜ë¦¬ì˜¤",
                "expected_status": "ì„¤ì • íŒŒê´´ ê°ì§€",
                "scenario_type": "inconsistent",
                "explanation": "[DRY-RUN] í…ŒìŠ¤íŠ¸ ì„¤ëª…",
                "novel_filename": novel
            }
        ])
    
    return dataset


def main():
    parser = argparse.ArgumentParser(description="RAG & Agent í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±")
    parser.add_argument("--dry-run", action="store_true", help="API í˜¸ì¶œ ì—†ì´ êµ¬ì¡°ë§Œ ê²€ì¦")
    parser.add_argument("--novels", type=int, default=5, help="ì‚¬ìš©í•  ì†Œì„¤ ìˆ˜ (ê¸°ë³¸: 5)")
    parser.add_argument("--qa-per-novel", type=int, default=10, help="ì†Œì„¤ë‹¹ QA ìŒ ìˆ˜ (ê¸°ë³¸: 10)")
    parser.add_argument("--agent-per-novel", type=int, default=6, help="ì†Œì„¤ë‹¹ Agent ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ (ê¸°ë³¸: 6)")
    parser.add_argument("--output", type=str, default=OUTPUT_FILE, help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()
    
    # ì†Œì„¤ ëª©ë¡ ë™ì  ìŠ¤ìº” (KR_*.txt)
    import glob
    novel_files = glob.glob(os.path.join(NOVEL_DIR, "KR_*.txt"))
    novels_to_use = [os.path.basename(f) for f in novel_files]
    
    # ì•¨ë¦¬ìŠ¤2ì¥ ë“± íŒŒí¸í™”ëœ íŒŒì¼ ì œì™¸ (ì„ íƒì )
    novels_to_use = [n for n in novels_to_use if "KR_" in n]
    novels_to_use.sort()
    
    if args.novels < len(novels_to_use):
        novels_to_use = novels_to_use[:args.novels]
    
    print(f"ğŸ“Š RAG & Agent í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±ê¸°")
    print(f"   ì†Œì„¤: {len(novels_to_use)}ê°œ")
    print(f"   RAG QA/ì†Œì„¤: {args.qa_per_novel}ê°œ")
    print(f"   Agent ì‹œë‚˜ë¦¬ì˜¤/ì†Œì„¤: {args.agent_per_novel}ê°œ")
    print(f"   ì¶œë ¥: {args.output}")
    print()
    
    # Dry-run ëª¨ë“œ
    if args.dry_run:
        print("ğŸƒ DRY-RUN ëª¨ë“œ: API í˜¸ì¶œ ì—†ì´ ë°ì´í„° êµ¬ì¡° ê²€ì¦")
        dataset = generate_dry_run_data(novels_to_use)
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        print(f"âœ… ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {args.output}")
        print(f"   RAG í‰ê°€: {len(dataset['rag_eval'])}ê°œ")
        print(f"   Agent í‰ê°€: {len(dataset['agent_eval'])}ê°œ")
        return
    
    # ì‹¤ì œ ì‹¤í–‰
    client = get_gemini_client()
    dataset = {"rag_eval": [], "agent_eval": []}
    
    for novel_filename in tqdm(novels_to_use, desc="ì†Œì„¤ ì²˜ë¦¬ ì¤‘"):
        filepath = os.path.join(NOVEL_DIR, novel_filename)
        if not os.path.exists(filepath):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filepath}, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        print(f"\nğŸ“– {novel_filename} ì²˜ë¦¬ ì¤‘...")
        text = load_novel_text(filepath)
        samples = extract_text_samples(text, num_samples=3)
        
        # RAG QA ìƒì„± (ì—¬ëŸ¬ ìƒ˜í”Œì—ì„œ ë¶„ì‚° ìƒì„±)
        qa_per_sample = max(1, args.qa_per_novel // len(samples))
        for i, sample in enumerate(samples):
            print(f"  [RAG] ìƒ˜í”Œ {i+1}/{len(samples)} ({qa_per_sample}ê°œ ìƒì„±)...")
            qa_pairs = generate_rag_qa_pairs(client, novel_filename, sample, qa_per_sample)
            for qa in qa_pairs:
                qa['novel_filename'] = novel_filename
                dataset['rag_eval'].append(qa)
        
        # Agent ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        print(f"  [Agent] ì‹œë‚˜ë¦¬ì˜¤ {args.agent_per_novel}ê°œ ìƒì„±...")
        scenarios = generate_agent_scenarios(client, novel_filename, samples[0], args.agent_per_novel)
        for sc in scenarios:
            sc['novel_filename'] = novel_filename
            dataset['agent_eval'].append(sc)
    
    # ì €ì¥
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {args.output}")
    print(f"   RAG í‰ê°€: {len(dataset['rag_eval'])}ê°œ")
    print(f"   Agent í‰ê°€: {len(dataset['agent_eval'])}ê°œ")
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    categories = {}
    for qa in dataset['rag_eval']:
        cat = qa.get('category', 'unknown')
        categories[cat] = categories.get(cat, 0) + 1
    print(f"   RAG ì¹´í…Œê³ ë¦¬ ë¶„í¬: {categories}")
    
    scenario_types = {}
    for sc in dataset['agent_eval']:
        st = sc.get('scenario_type', 'unknown')
        scenario_types[st] = scenario_types.get(st, 0) + 1
    print(f"   Agent ì‹œë‚˜ë¦¬ì˜¤ ë¶„í¬: {scenario_types}")


if __name__ == "__main__":
    main()
