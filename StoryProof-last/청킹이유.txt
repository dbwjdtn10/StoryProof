1. Child Chunk (검색용): "작고 날카롭게"
LLM이 읽는 게 아니라, 벡터 검색기(Retriever)가 '주인공이 마신 차 이름' 같은 디테일을 찾아내는 용도입니다.

추천 크기: 200 ~ 400 토큰 (한글 기준 약 300 ~ 600자)

단위: 문단(Paragraph) 2~3개 정도의 분량.

이유:

청크가 너무 크면, 그 안에 여러 주제(대화, 묘사, 독백)가 섞여서 벡터의 '의미'가 희석됩니다. (유사도 검색 정확도 하락)

소설의 구체적인 사건, 사물, 대사 하나하나가 검색에 걸리도록 작게 잡아야 합니다.

Overlap (중복): 50~100 토큰 정도를 겹치게 하여 문장이 중간에 잘려 의미가 끊기는 것을 방지하세요.

2. Parent Chunk (LLM 답변용): "크고 풍부하게"
검색된 Child가 속해 있는 '진짜 읽을거리'입니다. Gemini Flash는 컨텍스트가 매우 길기 때문에(100만 토큰 이상), 굳이 쪼개서 문맥을 해칠 필요가 없습니다.

추천 크기: 2,000 ~ 4,000 토큰 (한글 기준 약 3,000 ~ 6,000자)

단위: "장면(Scene)" 또는 "챕터(Chapter)" 단위가 가장 이상적입니다.

이유:

소설의 특성: 소설은 '앞뒤 문맥'이 생명입니다. "그가 웃었다"라는 문장의 의미는 그 앞의 10페이지에 걸친 사건을 알아야 "비웃음"인지 "기쁨"인지 파악할 수 있습니다.

모델의 장점 활용: Gemini Flash는 긴 글을 한 번에 처리하는 능력이 뛰어나고 비용도 저렴합니다. 굳이 짧게 잘라서 "누가 말하는 건지 모르는" 상황을 만들 필요가 없습니다.

4,000 토큰 정도면 소설책 10~15페이지 분량이므로, 웬만한 사건의 **'발단-전개-위기'**를 한 덩어리로 LLM에게 제공할 수 있습니다.